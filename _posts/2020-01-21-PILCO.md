---
layout: single
title: "PILCO: a data efficient policy search algorithm"
date: 2020-01-17
categories: control rl
permalink: "DERLMPC"
modified: 2020-01-22
description:
tags:
  - Staticman
  - Blog
header:
---

### Content
 1. [Introduction](#sec:intro)
 2. [Explanation](#sec:expl)
 3. [Implementation Details](#sec:impl)
 4. [Comments](#sec:disc)



## Introduction<a name="sec:intro"></a>

## Explanations<a name="sec:expl"></a>

## Implementation Details<a name="sec:impl"></a>

## Comments<a name="sec:disc"></a>

After running a couple of experiments, cart pole, double cart pole and double
pendulum, here are my impression. 
  1. The learning time is quite long ~2h for the double cart pole. It is
     obviously less than for deep nn but the algorithm barely finds a solution
     to the problem. 10 trials ~ 20s of interaction. They extend this to 30
     trials in the paper ~60s of interaction but this means more than 6h of
     optimisation as the number of training samples increase and GP are
     $$O(n^3)$$ for the prediction step where n is the number of training samples.
  2. Gradient descent on non-convex function is probably the main reasons for
     the poor solution. See figure 1.
  3. It feels like the Gaussian process struggles at learning the dynamics of the
     system mostly for high dimensonal systems. The uncertainty propagation after multiple rollouts given the
     policy is still extremely uncertain. See figure 2.
  4. Could reduce the learning time by throwing more computational power but
     this isn't a viable solution for real robot applications.
  5. I'm fairly certain that this algorithm will behave poorly on an AUV but I
     think that model-based RL with probabilistic model is a interesting path to
     follow. Main argument being that Model-Based rl are generally more data
     efficient (cite correct paper.) and optimisation under uncertainty seems to
     be intuitively more interesting, especially as **mean** models tend to make
     overconfident prediction in regions where there is no training sample which
     can be harmful for the agent or lead to suboptimal behaviors.
  6. More recent method make use of BNN or NN ensemble to estimate the
     uncertainty of the prediction. 
